#!/usr/bin/env python3
"""
Advanced Vulnerability Detection Module

This module provides comprehensive vulnerability detection capabilities by:
1. Loading enumeration reports from the reports/ directory
2. Parsing service information (ports, banners, versions)
3. Querying the OpenCVE API for relevant CVEs
4. Performing intelligent version comparison and filtering
5. Generating detailed JSON vulnerability reports

Usage: python3 vulnerability_detection.py <target>

Author: Security Scanner Backend
Version: 1.0.0
"""
import argparse
import json
import os
import sys
import logging
import re
import time
import requests
from datetime import datetime
from typing import Dict, List, Optional, Tuple, Any
from pathlib import Path
from urllib.parse import quote
import glob


class ServiceParser:
    """
    Extracts and normalizes service data from enumeration reports.
    
    This class handles parsing of various service information formats
    and normalizes them for vulnerability analysis.
    """
    
    def __init__(self, logger: logging.Logger):
        """Initialize the ServiceParser with a logger instance."""
        self.logger = logger
        
    def parse_report(self, report_data: Dict) -> List[Dict]:
        """
        Parse enumeration report and extract service information.
        
        Args:
            report_data (Dict): Raw report data from JSON file
            
        Returns:
            List[Dict]: List of normalized service dictionaries
        """
        services = []
        
        try:
            # Handle different report formats
            if 'ports' in report_data:
                services.extend(self._parse_port_based_report(report_data['ports']))
            elif 'scan_results' in report_data:
                services.extend(self._parse_scan_results(report_data['scan_results']))
            elif 'services' in report_data:
                services.extend(self._parse_services_direct(report_data['services']))
            else:
                # Try to parse any port-like data found in the report
                services.extend(self._parse_generic_report(report_data))
                
            self.logger.info(f"Parsed {len(services)} services from report")
            return services
            
        except Exception as e:
            self.logger.error(f"Error parsing report: {str(e)}")
            return []
    
    def _parse_port_based_report(self, ports_data: Dict) -> List[Dict]:
        """Parse port-based enumeration reports (e.g., Nmap format)."""
        services = []
        
        for port, port_info in ports_data.items():
            if isinstance(port_info, dict) and port_info.get('state') == 'open':
                service = self._normalize_service_info(port, port_info)
                if service:
                    services.append(service)
                    
        return services
    
    def _parse_scan_results(self, scan_data: Dict) -> List[Dict]:
        """Parse scan results format."""
        services = []
        
        for host, host_data in scan_data.items():
            if 'ports' in host_data:
                for port_info in host_data['ports']:
                    service = self._normalize_service_info(
                        port_info.get('port'), port_info
                    )
                    if service:
                        services.append(service)
                        
        return services
    
    def _parse_services_direct(self, services_data: List) -> List[Dict]:
        """Parse direct services list format."""
        services = []
        
        for service_info in services_data:
            service = self._normalize_service_info(
                service_info.get('port'), service_info
            )
            if service:
                services.append(service)
                
        return services
    
    def _parse_generic_report(self, report_data: Dict) -> List[Dict]:
        """Attempt to parse any generic report format."""
        services = []
        
        # Look for common keys that might contain service information
        for key, value in report_data.items():
            if isinstance(value, dict):
                for sub_key, sub_value in value.items():
                    if 'port' in str(sub_key).lower() or 'service' in str(sub_key).lower():
                        service = self._normalize_service_info(sub_key, sub_value)
                        if service:
                            services.append(service)
                            
        return services
    
    def _normalize_service_info(self, port: str, port_info: Dict) -> Optional[Dict]:
        """
        Normalize service information into a standard format.
        
        Args:
            port (str): Port number or identifier
            port_info (Dict): Raw port/service information
            
        Returns:
            Optional[Dict]: Normalized service dictionary or None
        """
        try:
            # Extract port number
            port_num = self._extract_port_number(port)
            if not port_num:
                return None
            
            # Extract service name
            service_name = (
                port_info.get('service') or 
                port_info.get('name') or 
                port_info.get('service_name') or
                'unknown'
            )
            
            # Extract version information
            version_info = self._extract_version_info(port_info)
            
            # Extract banner information
            banner = (
                port_info.get('banner') or 
                port_info.get('version') or 
                port_info.get('product') or
                ''
            )
            
            normalized_service = {
                'port': port_num,
                'service': service_name.lower(),
                'protocol': port_info.get('protocol', 'tcp').lower(),
                'state': port_info.get('state', 'open'),
                'banner': banner,
                'product': version_info.get('product', ''),
                'version': version_info.get('version', ''),
                'vendor': version_info.get('vendor', ''),
                'cpe': version_info.get('cpe', ''),
                'raw_info': port_info
            }
            
            return normalized_service
            
        except Exception as e:
            self.logger.warning(f"Error normalizing service info for port {port}: {str(e)}")
            return None
    
    def _extract_port_number(self, port: str) -> Optional[int]:
        """Extract numeric port number from various formats."""
        try:
            # Handle different port formats
            if isinstance(port, int):
                return port
            elif isinstance(port, str):
                # Extract number from strings like "80/tcp", "443", "port_80"
                match = re.search(r'(\d+)', str(port))
                if match:
                    return int(match.group(1))
            return None
        except:
            return None
    
    def _extract_version_info(self, port_info: Dict) -> Dict[str, str]:
        """Extract detailed version information from port data."""
        version_info = {
            'product': '',
            'version': '',
            'vendor': '',
            'cpe': ''
        }
        
        # Direct field extraction
        version_info['product'] = port_info.get('product', '')
        version_info['version'] = port_info.get('version', '')
        version_info['vendor'] = port_info.get('vendor', '')
        version_info['cpe'] = port_info.get('cpe', '')
        
        # Parse from banner if available
        banner = port_info.get('banner', '') or port_info.get('version', '')
        if banner:
            parsed_info = self._parse_banner_version(banner)
            for key, value in parsed_info.items():
                if value and not version_info[key]:
                    version_info[key] = value
        
        return version_info
    
    def _parse_banner_version(self, banner: str) -> Dict[str, str]:
        """Parse version information from service banners."""
        info = {'product': '', 'version': '', 'vendor': ''}
        
        # Common patterns for version extraction
        patterns = [
            r'(\w+)/(\d+(?:\.\d+)*)',  # Apache/2.4.41
            r'(\w+)\s+(\d+(?:\.\d+)*)',  # OpenSSH 7.4
            r'(\w+)-(\d+(?:\.\d+)*)',  # nginx-1.18.0
            r'Microsoft\s+(\w+)\s+(\d+(?:\.\d+)*)',  # Microsoft IIS 10.0
        ]
        
        for pattern in patterns:
            match = re.search(pattern, banner, re.IGNORECASE)
            if match:
                info['product'] = match.group(1)
                info['version'] = match.group(2)
                break
        
        # Extract vendor information
        vendor_patterns = [
            r'Microsoft',
            r'Apache',
            r'nginx',
            r'OpenSSH'
        ]
        
        for vendor_pattern in vendor_patterns:
            if re.search(vendor_pattern, banner, re.IGNORECASE):
                info['vendor'] = vendor_pattern.lower()
                break
        
        return info


class CVEAnalyzer:
    """
    Queries OpenCVE API, matches CVEs, filters, and analyzes vulnerabilities.
    
    This class handles all CVE-related operations including API queries,
    version comparison, and vulnerability filtering.
    """
    
    def __init__(self, logger: logging.Logger):
        """Initialize the CVE analyzer with logging and caching."""
        self.logger = logger
        self.base_url = "https://www.opencve.io/api"
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'VulnerabilityScanner/1.0',
            'Accept': 'application/json'
        })
        self.cache = {}  # Runtime cache for API responses
        self.rate_limit_delay = 1  # Seconds between requests
        
    def analyze_service_vulnerabilities(self, service: Dict) -> List[Dict]:
        """
        Analyze a service for vulnerabilities.
        
        Args:
            service (Dict): Normalized service information
            
        Returns:
            List[Dict]: List of relevant CVEs with analysis
        """
        vulnerabilities = []
        
        try:
            # Generate search terms for the service
            search_terms = self._generate_search_terms(service)
            
            # Query CVEs for each search term
            for term in search_terms:
                cves = self._query_cves_for_product(term, service)
                vulnerabilities.extend(cves)
            
            # Remove duplicates based on CVE ID
            unique_cves = self._deduplicate_cves(vulnerabilities)
            
            # Filter and score CVEs
            filtered_cves = self._filter_and_score_cves(unique_cves, service)
            
            self.logger.info(f"Found {len(filtered_cves)} relevant CVEs for {service['service']} on port {service['port']}")
            return filtered_cves
            
        except Exception as e:
            self.logger.error(f"Error analyzing vulnerabilities for service {service['service']}: {str(e)}")
            return []
    
    def _generate_search_terms(self, service: Dict) -> List[str]:
        """Generate search terms for CVE queries based on service info."""
        terms = []
        
        # Add product name if available
        if service['product']:
            terms.append(service['product'].lower())
        
        # Add service name
        if service['service'] and service['service'] != 'unknown':
            terms.append(service['service'].lower())
        
        # Add vendor if available
        if service['vendor']:
            terms.append(service['vendor'].lower())
        
        # Parse additional terms from banner
        banner_terms = self._extract_search_terms_from_banner(service['banner'])
        terms.extend(banner_terms)
        
        # Remove duplicates and empty terms
        terms = list(set([term for term in terms if term and len(term) > 2]))
        
        return terms[:5]  # Limit to 5 terms to avoid excessive API calls
    
    def _extract_search_terms_from_banner(self, banner: str) -> List[str]:
        """Extract potential product names from service banners."""
        if not banner:
            return []
        
        terms = []
        
        # Common software patterns
        patterns = [
            r'(Apache|nginx|IIS|OpenSSH|vsftpd|ProFTPD|MySQL|PostgreSQL|MongoDB)',
            r'(\w+)/\d+\.\d+',  # Software/version patterns
            r'(\w+)-\d+\.\d+',  # Software-version patterns
        ]
        
        for pattern in patterns:
            matches = re.findall(pattern, banner, re.IGNORECASE)
            for match in matches:
                if isinstance(match, tuple):
                    terms.extend([m.lower() for m in match if m])
                else:
                    terms.append(match.lower())
        
        return terms
    
    def _query_cves_for_product(self, product_name: str, service: Dict) -> List[Dict]:
        """
        Query OpenCVE API for CVEs related to a specific product.
        
        Args:
            product_name (str): Product name to search for
            service (Dict): Service information for context
            
        Returns:
            List[Dict]: List of CVE dictionaries
        """
        # Check cache first
        cache_key = f"cve_{product_name}"
        if cache_key in self.cache:
            self.logger.debug(f"Using cached CVEs for {product_name}")
            return self.cache[cache_key]
        
        cves = []
        page = 1
        max_pages = 10  # Limit to prevent excessive API calls
        
        try:
            while page <= max_pages:
                # Respect rate limits
                time.sleep(self.rate_limit_delay)
                
                # Construct API URL with search parameters
                url = f"{self.base_url}/cve"
                params = {
                    'search': product_name,
                    'page': page,
                    'per_page': 100  # Maximum per page
                }
                
                self.logger.debug(f"Querying CVEs for {product_name}, page {page}")
                
                response = self.session.get(url, params=params, timeout=30)
                
                if response.status_code == 429:  # Rate limited
                    self.logger.warning("Rate limited, increasing delay")
                    self.rate_limit_delay *= 2
                    time.sleep(self.rate_limit_delay)
                    continue
                elif response.status_code != 200:
                    self.logger.warning(f"API request failed with status {response.status_code}")
                    break
                
                data = response.json()
                
                # Handle different response formats
                if isinstance(data, list):
                    page_cves = data
                elif isinstance(data, dict) and 'data' in data:
                    page_cves = data['data']
                else:
                    self.logger.warning("Unexpected API response format")
                    break
                
                if not page_cves:
                    break  # No more results
                
                # Process CVEs from this page
                for cve_data in page_cves:
                    processed_cve = self._process_cve_data(cve_data)
                    if processed_cve:
                        cves.append(processed_cve)
                
                # Check if there are more pages
                if len(page_cves) < params['per_page']:
                    break
                
                page += 1
                
        except requests.RequestException as e:
            self.logger.error(f"Network error querying CVEs for {product_name}: {str(e)}")
        except Exception as e:
            self.logger.error(f"Error querying CVEs for {product_name}: {str(e)}")
        
        # Cache results
        self.cache[cache_key] = cves
        self.logger.info(f"Retrieved {len(cves)} CVEs for {product_name}")
        
        return cves
    
    def _process_cve_data(self, cve_data: Dict) -> Optional[Dict]:
        """Process raw CVE data into normalized format."""
        try:
            # Extract basic CVE information
            cve_id = cve_data.get('id') or cve_data.get('cve_id', '')
            
            if not cve_id:
                return None
            
            # Extract CVSS information
            cvss_data = cve_data.get('cvss', {})
            if isinstance(cvss_data, dict):
                cvss_score = cvss_data.get('score', 0.0)
                cvss_vector = cvss_data.get('vector', '')
                cvss_severity = cvss_data.get('severity', 'UNKNOWN')
            else:
                cvss_score = 0.0
                cvss_vector = ''
                cvss_severity = 'UNKNOWN'
            
            # Extract CWE information
            cwes = []
            if 'cwes' in cve_data:
                cwes = cve_data['cwes']
            elif 'cwe' in cve_data:
                cwe_data = cve_data['cwe']
                if isinstance(cwe_data, list):
                    cwes = cwe_data
                elif isinstance(cwe_data, str):
                    cwes = [cwe_data]
            
            processed_cve = {
                'cve_id': cve_id,
                'description': cve_data.get('summary', cve_data.get('description', '')),
                'published_date': cve_data.get('published', ''),
                'modified_date': cve_data.get('modified', ''),
                'cvss': {
                    'score': float(cvss_score),
                    'vector': cvss_vector,
                    'severity': cvss_severity
                },
                'cwes': cwes,
                'references': cve_data.get('references', []),
                'affected_products': cve_data.get('vendors', {}),
                'raw_data': cve_data
            }
            
            return processed_cve
            
        except Exception as e:
            self.logger.warning(f"Error processing CVE data: {str(e)}")
            return None
    
    def _deduplicate_cves(self, cves: List[Dict]) -> List[Dict]:
        """Remove duplicate CVEs based on CVE ID."""
        seen_ids = set()
        unique_cves = []
        
        for cve in cves:
            cve_id = cve['cve_id']
            if cve_id not in seen_ids:
                seen_ids.add(cve_id)
                unique_cves.append(cve)
        
        return unique_cves
    
    def _filter_and_score_cves(self, cves: List[Dict], service: Dict) -> List[Dict]:
        """Filter and score CVEs based on relevance and severity."""
        filtered_cves = []
        
        for cve in cves:
            # Apply basic filters
            if not self._passes_basic_filters(cve):
                continue
            
            # Check version compatibility
            version_match = self._check_version_compatibility(cve, service)
            
            # Calculate relevance score
            relevance_score = self._calculate_relevance_score(cve, service)
            
            # Add analysis metadata
            cve['analysis'] = {
                'version_match': version_match,
                'relevance_score': relevance_score,
                'severity_level': self._get_severity_level(cve['cvss']['score']),
                'risk_level': self._calculate_risk_level(cve, relevance_score)
            }
            
            filtered_cves.append(cve)
        
        # Sort by CVSS score and relevance
        filtered_cves.sort(
            key=lambda x: (x['cvss']['score'], x['analysis']['relevance_score']), 
            reverse=True
        )
        
        return filtered_cves
    
    def _passes_basic_filters(self, cve: Dict) -> bool:
        """Apply basic filters to CVEs."""
        # Filter by minimum CVSS score (configurable threshold)
        min_cvss_score = 4.0
        if cve['cvss']['score'] < min_cvss_score:
            return False
        
        # Filter out very old CVEs (older than 10 years)
        try:
            published_year = int(cve['published_date'][:4])
            current_year = datetime.now().year
            if current_year - published_year > 10:
                return False
        except:
            pass  # Keep CVE if date parsing fails
        
        return True
    
    def _check_version_compatibility(self, cve: Dict, service: Dict) -> str:
        """Check if the service version is affected by the CVE."""
        if not service['version']:
            return 'unknown'
        
        try:
            service_version = service['version']
            
            # Look for version information in CVE description
            description = cve['description'].lower()
            
            # Simple version comparison patterns
            version_patterns = [
                rf"before\s+{re.escape(service_version)}",
                rf"prior\s+to\s+{re.escape(service_version)}",
                rf"through\s+{re.escape(service_version)}",
                rf"up\s+to\s+{re.escape(service_version)}"
            ]
            
            for pattern in version_patterns:
                if re.search(pattern, description):
                    return 'likely_vulnerable'
            
            # Check affected products for version ranges
            affected_products = cve.get('affected_products', {})
            for vendor, products in affected_products.items():
                for product, versions in products.items():
                    if self._is_version_in_range(service_version, versions):
                        return 'vulnerable'
            
            return 'possible'
            
        except Exception as e:
            self.logger.debug(f"Error checking version compatibility: {str(e)}")
            return 'unknown'
    
    def _is_version_in_range(self, version: str, version_ranges: List) -> bool:
        """Check if a version falls within vulnerable ranges."""
        # Simplified version comparison - in production, use proper version parsing
        try:
            version_parts = [int(x) for x in version.split('.')]
            
            for version_range in version_ranges:
                # This is a simplified implementation
                # In production, use a proper version comparison library
                if version in str(version_range):
                    return True
            
            return False
        except:
            return False
    
    def _calculate_relevance_score(self, cve: Dict, service: Dict) -> float:
        """Calculate relevance score for CVE based on service information."""
        score = 0.0
        
        description = cve['description'].lower()
        
        # Check for exact product matches
        if service['product'] and service['product'].lower() in description:
            score += 3.0
        
        # Check for service name matches
        if service['service'] and service['service'] in description:
            score += 2.0
        
        # Check for vendor matches
        if service['vendor'] and service['vendor'].lower() in description:
            score += 1.5
        
        # Check for port-specific vulnerabilities
        port_str = str(service['port'])
        if port_str in description:
            score += 1.0
        
        # Bonus for recent CVEs
        try:
            published_year = int(cve['published_date'][:4])
            current_year = datetime.now().year
            years_old = current_year - published_year
            if years_old < 2:
                score += 1.0
            elif years_old < 5:
                score += 0.5
        except:
            pass
        
        return score
    
    def _get_severity_level(self, cvss_score: float) -> str:
        """Convert CVSS score to severity level."""
        if cvss_score >= 9.0:
            return 'CRITICAL'
        elif cvss_score >= 7.0:
            return 'HIGH'
        elif cvss_score >= 4.0:
            return 'MEDIUM'
        elif cvss_score > 0.0:
            return 'LOW'
        else:
            return 'INFORMATIONAL'
    
    def _calculate_risk_level(self, cve: Dict, relevance_score: float) -> str:
        """Calculate overall risk level combining CVSS and relevance."""
        cvss_score = cve['cvss']['score']
        
        # Weighted risk calculation
        risk_score = (cvss_score * 0.7) + (relevance_score * 0.3)
        
        if risk_score >= 8.0:
            return 'CRITICAL'
        elif risk_score >= 6.0:
            return 'HIGH'
        elif risk_score >= 4.0:
            return 'MEDIUM'
        else:
            return 'LOW'


class ReportGenerator:
    """
    Formats and writes JSON vulnerability reports.
    
    This class handles the generation of comprehensive vulnerability reports
    in JSON format with proper structure and metadata.
    """
    
    def __init__(self, logger: logging.Logger, output_dir: str = "jsonreports"):
        """Initialize the report generator."""
        self.logger = logger
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True)
    
    def generate_report(self, target: str, services: List[Dict], 
                       vulnerability_results: Dict[str, List[Dict]]) -> str:
        """
        Generate comprehensive vulnerability report.
        
        Args:
            target (str): Target identifier
            services (List[Dict]): List of discovered services
            vulnerability_results (Dict): Mapping of service keys to vulnerabilities
            
        Returns:
            str: Path to generated report file
        """
        try:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"vulnreport_{target}_{timestamp}.json"
            filepath = self.output_dir / filename
            
            # Build comprehensive report structure
            report = {
                "metadata": {
                    "target": target,
                    "scan_timestamp": datetime.now().isoformat(),
                    "report_version": "1.0",
                    "generator": "VulnerabilityDetector",
                    "total_services": len(services),
                    "total_vulnerabilities": sum(len(vulns) for vulns in vulnerability_results.values())
                },
                "executive_summary": self._generate_executive_summary(services, vulnerability_results),
                "services": services,
                "vulnerabilities": self._organize_vulnerabilities(vulnerability_results),
                "statistics": self._generate_statistics(vulnerability_results),
                "recommendations": self._generate_recommendations(vulnerability_results)
            }
            
            # Write report to file
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(report, f, indent=2, ensure_ascii=False, default=str)
            
            self.logger.info(f"Vulnerability report generated: {filepath}")
            return str(filepath)
            
        except Exception as e:
            self.logger.error(f"Error generating report: {str(e)}")
            raise
    
    def _generate_executive_summary(self, services: List[Dict], 
                                   vulnerability_results: Dict[str, List[Dict]]) -> Dict:
        """Generate executive summary of findings."""
        total_vulns = sum(len(vulns) for vulns in vulnerability_results.values())
        
        # Count vulnerabilities by severity
        severity_counts = {'CRITICAL': 0, 'HIGH': 0, 'MEDIUM': 0, 'LOW': 0}
        
        for vulns in vulnerability_results.values():
            for vuln in vulns:
                severity = vuln['analysis']['severity_level']
                if severity in severity_counts:
                    severity_counts[severity] += 1
        
        # Identify high-risk services
        high_risk_services = []
        for service_key, vulns in vulnerability_results.items():
            critical_high_vulns = [
                v for v in vulns 
                if v['analysis']['severity_level'] in ['CRITICAL', 'HIGH']
            ]
            if critical_high_vulns:
                high_risk_services.append({
                    'service': service_key,
                    'critical_vulnerabilities': len([v for v in critical_high_vulns if v['analysis']['severity_level'] == 'CRITICAL']),
                    'high_vulnerabilities': len([v for v in critical_high_vulns if v['analysis']['severity_level'] == 'HIGH'])
                })
        
        return {
            "total_services_scanned": len(services),
            "total_vulnerabilities_found": total_vulns,
            "severity_breakdown": severity_counts,
            "high_risk_services": high_risk_services,
            "scan_coverage": f"{len([s for s in services if s['service'] != 'unknown'])}/{len(services)} services identified"
        }
    
    def _organize_vulnerabilities(self, vulnerability_results: Dict[str, List[Dict]]) -> Dict:
        """Organize vulnerabilities by service and severity."""
        organized = {}
        
        for service_key, vulns in vulnerability_results.items():
            if not vulns:
                continue
                
            organized[service_key] = {
                "service_info": service_key,
                "vulnerability_count": len(vulns),
                "vulnerabilities": sorted(vulns, key=lambda x: x['cvss']['score'], reverse=True)
            }
        
        return organized
    
    def _generate_statistics(self, vulnerability_results: Dict[str, List[Dict]]) -> Dict:
        """Generate detailed statistics about vulnerabilities."""
        all_vulns = []
        for vulns in vulnerability_results.values():
            all_vulns.extend(vulns)
        
        if not all_vulns:
            return {"message": "No vulnerabilities found"}
        
        # CVSS score statistics
        cvss_scores = [v['cvss']['score'] for v in all_vulns if v['cvss']['score'] > 0]
        
        # CWE analysis
        cwe_counts = {}
        for vuln in all_vulns:
            for cwe in vuln.get('cwes', []):
                cwe_counts[cwe] = cwe_counts.get(cwe, 0) + 1
        
        # Top CVEs by score
        top_cves = sorted(all_vulns, key=lambda x: x['cvss']['score'], reverse=True)[:10]
        
        stats = {
            "total_unique_cves": len(set(v['cve_id'] for v in all_vulns)),
            "cvss_statistics": {
                "average_score": sum(cvss_scores) / len(cvss_scores) if cvss_scores else 0,
                "highest_score": max(cvss_scores) if cvss_scores else 0,
                "lowest_score": min(cvss_scores) if cvss_scores else 0
            },
            "top_cwes": sorted(cwe_counts.items(), key=lambda x: x[1], reverse=True)[:10],
            "top_cves_by_score": [
                {
                    "cve_id": cve['cve_id'],
                    "cvss_score": cve['cvss']['score'],
                    "severity": cve['analysis']['severity_level']
                }
                for cve in top_cves
            ]
        }
        return stats
    def _generate_recommendations(self, vulnerability_results: Dict[str, List[Dict]]) -> List[Dict]:
        """Generate security recommendations based on vulnerabilities found."""
        recommendations = []
        
        # Collect all vulnerabilities for analysis
        all_vulns = []
        for vulns in vulnerability_results.values():
            all_vulns.extend(vulns)
        
        if not all_vulns:
            return [{"priority": "INFO", "category": "General", "message": "No vulnerabilities detected in current scan"}]
        
        # Critical vulnerabilities recommendations
        critical_vulns = [v for v in all_vulns if v['analysis']['severity_level'] == 'CRITICAL']
        if critical_vulns:
            recommendations.append({
                "priority": "CRITICAL",
                "category": "Immediate Action Required",
                "message": f"Found {len(critical_vulns)} critical vulnerabilities requiring immediate attention",
                "action": "Patch or disable affected services immediately"
            })
        
        # High severity recommendations
        high_vulns = [v for v in all_vulns if v['analysis']['severity_level'] == 'HIGH']
        if high_vulns:
            recommendations.append({
                "priority": "HIGH",
                "category": "Urgent Patching",
                "message": f"Found {len(high_vulns)} high-severity vulnerabilities",
                "action": "Schedule patching within 72 hours"
            })
        
        # Service-specific recommendations
        service_recommendations = self._generate_service_recommendations(vulnerability_results)
        recommendations.extend(service_recommendations)
        
        return recommendations
    
    def _generate_service_recommendations(self, vulnerability_results: Dict[str, List[Dict]]) -> List[Dict]:
        """Generate service-specific security recommendations."""
        recommendations = []
        
        for service_key, vulns in vulnerability_results.items():
            if not vulns:
                continue
            
            # Parse service information from key
            service_info = service_key.split(':')
            if len(service_info) >= 2:
                service_name = service_info[1]
                
                # Service-specific recommendations
                if 'ssh' in service_name.lower():
                    recommendations.append({
                        "priority": "MEDIUM",
                        "category": "SSH Security",
                        "message": f"SSH service has {len(vulns)} vulnerabilities",
                        "action": "Update SSH version, disable root login, use key-based authentication"
                    })
                elif 'http' in service_name.lower() or 'apache' in service_name.lower() or 'nginx' in service_name.lower():
                    recommendations.append({
                        "priority": "MEDIUM",
                        "category": "Web Service Security",
                        "message": f"Web service has {len(vulns)} vulnerabilities",
                        "action": "Update web server, review security configurations, enable HTTPS"
                    })
                elif 'ftp' in service_name.lower():
                    recommendations.append({
                        "priority": "HIGH",
                        "category": "FTP Security",
                        "message": f"FTP service has {len(vulns)} vulnerabilities",
                        "action": "Consider replacing FTP with SFTP/FTPS, update FTP server"
                    })
        
        return recommendations


class VulnerabilityDetector:
    """
    Main orchestrator class for vulnerability detection process.
    
    This class coordinates the entire vulnerability detection workflow by:
    1. Loading enumeration reports from the reports directory
    2. Parsing service information using ServiceParser
    3. Analyzing vulnerabilities using CVEAnalyzer
    4. Generating comprehensive reports using ReportGenerator
    """
    
    def __init__(self, reports_dir: str = "reports", output_dir: str = "jsonreports"):
        """
        Initialize the VulnerabilityDetector.
        
        Args:
            reports_dir (str): Directory containing enumeration reports
            output_dir (str): Directory for output JSON reports
        """
        self.reports_dir = Path(reports_dir)
        self.output_dir = Path(output_dir)
        
        # Setup logging
        self.logger = self._setup_logging()
        
        # Initialize components
        self.service_parser = ServiceParser(self.logger)
        self.cve_analyzer = CVEAnalyzer(self.logger)
        self.report_generator = ReportGenerator(self.logger, str(output_dir))
        
        # Ensure directories exist
        self.reports_dir.mkdir(exist_ok=True)
        self.output_dir.mkdir(exist_ok=True)
    
    def _setup_logging(self) -> logging.Logger:
        """Configure logging for the vulnerability detector."""
        logger = logging.getLogger('VulnerabilityDetector')
        logger.setLevel(logging.INFO)
        
        # Only log to file, not console (to keep output clean)
        log_file = Path('vulnerability_detection.log')
        handler = logging.FileHandler(log_file)
        formatter = logging.Formatter(
            '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        )
        handler.setFormatter(formatter)
        
        # Clear existing handlers to avoid duplicate logs
        logger.handlers.clear()
        logger.addHandler(handler)
        
        return logger
    
    def detect_vulnerabilities(self, target: str) -> str:
        """
        Main vulnerability detection process for a target.
        
        Args:
            target (str): Target identifier to analyze
            
        Returns:
            str: Path to generated vulnerability report
            
        Raises:
            FileNotFoundError: If no enumeration report found for target
            Exception: For other processing errors
        """
        try:
            self.logger.info(f"Starting vulnerability detection for target: {target}")
            
            # Step 1: Find and load the latest enumeration report
            report_file = self._find_latest_report(target)
            report_data = self._load_report(report_file)
            
            # Step 2: Parse services from the report
            services = self.service_parser.parse_report(report_data)
            
            if not services:
                self.logger.warning(f"No services found in report for target {target}")
                # Still generate a report with empty results
                services = []
            
            # Step 3: Analyze vulnerabilities for each service
            vulnerability_results = {}
            
            for service in services:
                service_key = f"{service['port']}:{service['service']}"
                self.logger.info(f"Analyzing vulnerabilities for {service_key}")
                
                try:
                    vulns = self.cve_analyzer.analyze_service_vulnerabilities(service)
                    vulnerability_results[service_key] = vulns
                    
                    self.logger.info(f"Found {len(vulns)} vulnerabilities for {service_key}")
                    
                except Exception as e:
                    self.logger.error(f"Error analyzing {service_key}: {str(e)}")
                    vulnerability_results[service_key] = []
            
            # Step 4: Generate comprehensive report
            report_path = self.report_generator.generate_report(
                target, services, vulnerability_results
            )
            
            # Summary for user (JSON-only output)
            total_vulns = sum(len(vulns) for vulns in vulnerability_results.values())
            summary = {
                "status": "completed",
                "target": target,
                "services_analyzed": len(services),
                "total_vulnerabilities": total_vulns,
                "report_location": report_path,
                "timestamp": datetime.now().isoformat()
            }
            
            # Output summary as JSON to stdout
            print(json.dumps(summary, indent=2))
            
            self.logger.info(f"Vulnerability detection completed for {target}")
            return report_path
            
        except FileNotFoundError as e:
            error_msg = f"No enumeration report found for target '{target}'"
            self.logger.error(error_msg)
            error_output = {
                "status": "error",
                "target": target,
                "error": error_msg,
                "timestamp": datetime.now().isoformat()
            }
            print(json.dumps(error_output, indent=2))
            raise
            
        except Exception as e:
            error_msg = f"Error processing target '{target}': {str(e)}"
            self.logger.error(error_msg)
            error_output = {
                "status": "error",
                "target": target,
                "error": error_msg,
                "timestamp": datetime.now().isoformat()
            }
            print(json.dumps(error_output, indent=2))
            raise
    
    def _find_latest_report(self, target: str) -> Path:
        """
        Find the latest enumeration report for a target.
        
        Args:
            target (str): Target identifier
            
        Returns:
            Path: Path to the latest report file
            
        Raises:
            FileNotFoundError: If no report found for target
        """
        # Look for report files matching the target
        patterns = [
            f"*{target}*.json",
            f"{target}_*.json",
            f"enum_{target}*.json",
            f"scan_{target}*.json",
            f"nmap_{target}*.json"
        ]
        
        matching_files = []
        for pattern in patterns:
            matching_files.extend(self.reports_dir.glob(pattern))
        
        if not matching_files:
            # Try case-insensitive search
            all_files = list(self.reports_dir.glob("*.json"))
            matching_files = [
                f for f in all_files 
                if target.lower() in f.name.lower()
            ]
        
        if not matching_files:
            raise FileNotFoundError(f"No enumeration report found for target '{target}' in {self.reports_dir}")
        
        # Return the most recently modified file
        latest_file = max(matching_files, key=lambda f: f.stat().st_mtime)
        self.logger.info(f"Using report file: {latest_file}")
        
        return latest_file
    
    def _load_report(self, report_file: Path) -> Dict:
        """
        Load and validate enumeration report from JSON file.
        
        Args:
            report_file (Path): Path to report file
            
        Returns:
            Dict: Loaded report data
            
        Raises:
            Exception: If file cannot be loaded or parsed
        """
        try:
            with open(report_file, 'r', encoding='utf-8') as f:
                report_data = json.load(f)
            
            self.logger.info(f"Successfully loaded report: {report_file}")
            return report_data
            
        except json.JSONDecodeError as e:
            raise Exception(f"Invalid JSON in report file {report_file}: {str(e)}")
        except Exception as e:
            raise Exception(f"Error loading report file {report_file}: {str(e)}")
    
    def list_available_targets(self) -> List[str]:
        """
        List all available targets based on report files.
        
        Returns:
            List[str]: List of target identifiers
        """
        targets = set()
        
        # Scan for JSON files in reports directory
        for report_file in self.reports_dir.glob("*.json"):
            # Extract potential target names from filename
            filename = report_file.stem
            
            # Common patterns for target extraction
            patterns = [
                r'enum_(.+?)_\d{8}',
                r'scan_(.+?)_\d{8}',
                r'nmap_(.+?)_\d{8}',
                r'(.+?)_\d{8}_\d{6}',
                r'(.+?)_enum',
                r'(.+?)_scan'
            ]
            
            for pattern in patterns:
                match = re.search(pattern, filename)
                if match:
                    targets.add(match.group(1))
                    break
        
        return sorted(list(targets))


def main():
    """
    Main entry point for the vulnerability detection script.
    
    Handles command-line arguments and orchestrates the detection process.
    """
    parser = argparse.ArgumentParser(
        description="Vulnerability Detection Tool - Analyze enumeration reports for CVEs",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  python3 vulnerability_detection.py 192.168.1.100
  python3 vulnerability_detection.py webserver-01
  python3 vulnerability_detection.py --list-targets
        """
    )
    
    parser.add_argument(
        'target',
        nargs='?',
        help='Target identifier to analyze (matches report filename)'
    )
    
    parser.add_argument(
        '--list-targets',
        action='store_true',
        help='List all available targets from reports directory'
    )
    
    parser.add_argument(
        '--reports-dir',
        default='reports',
        help='Directory containing enumeration reports (default: reports)'
    )
    
    parser.add_argument(
        '--output-dir',
        default='jsonreports',
        help='Directory for output JSON reports (default: jsonreports)'
    )
    
    args = parser.parse_args()
    
    try:
        # Initialize vulnerability detector
        detector = VulnerabilityDetector(
            reports_dir=args.reports_dir,
            output_dir=args.output_dir
        )
        
        # Handle list targets option
        if args.list_targets:
            targets = detector.list_available_targets()
            output = {
                "available_targets": targets,
                "total_count": len(targets),
                "timestamp": datetime.now().isoformat()
            }
            print(json.dumps(output, indent=2))
            return
        
        # Validate target argument
        if not args.target:
            error_output = {
                "status": "error",
                "error": "Target argument required. Use --list-targets to see available options.",
                "usage": "python3 vulnerability_detection.py <target>",
                "timestamp": datetime.now().isoformat()
            }
            print(json.dumps(error_output, indent=2))
            sys.exit(1)
        
        # Run vulnerability detection
        report_path = detector.detect_vulnerabilities(args.target)
        
        # Success - summary already printed by detect_vulnerabilities
        sys.exit(0)
        
    except KeyboardInterrupt:
        error_output = {
            "status": "interrupted",
            "message": "Vulnerability detection interrupted by user",
            "timestamp": datetime.now().isoformat()
        }
        print(json.dumps(error_output, indent=2))
        sys.exit(130)
        
    except FileNotFoundError:
        # Error already handled and printed in detect_vulnerabilities
        sys.exit(1)
        
    except Exception as e:
        error_output = {
            "status": "fatal_error",
            "error": str(e),
            "timestamp": datetime.now().isoformat()
        }
        print(json.dumps(error_output, indent=2))
        sys.exit(1)


if __name__ == "__main__":
    main()